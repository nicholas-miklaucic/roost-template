{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import rho_plus as rp\n",
    "\n",
    "theme, cs = rp.mpl_setup(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  -U git+https://github.com/CompRhys/aviary.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather('pairs_data.feather')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elem_embs = pd.read_json('https://raw.githubusercontent.com/CompRhys/aviary/refs/heads/main/aviary/embeddings/element/megnet16.json')\n",
    "elem_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from aviary.roost.model import DescriptorNetwork\n",
    "from pymatgen.core import Composition\n",
    "from torch import Tensor, LongTensor\n",
    "from data import collate_batch, comp2graph\n",
    "\n",
    "device = 'cuda'\n",
    "torch.set_default_device(device)\n",
    "\n",
    "\n",
    "\n",
    "elem_embed_dim = 112\n",
    "comp_embed_dim = 64\n",
    "\n",
    "batch = collate_batch([comp2graph(x) for x in df.sample(16)['pretty_formula_1']])\n",
    "print([tuple(x.shape) for x in batch])\n",
    "\n",
    "gnn = DescriptorNetwork(elem_emb_len=elem_embed_dim, elem_fea_len=64)\n",
    "\n",
    "out = gnn(*batch)\n",
    "\n",
    "print(out.shape)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = pd.read_csv('https://raw.githubusercontent.com/usccolumbia/cspbenchmark/main/data/CSPbenchmark_test_data.csv')\n",
    "benchmark_ids = benchmark['material_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, IterableDataset\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "fn = 'ds-oh.pt'\n",
    "regen = False\n",
    "\n",
    "val_frac = 0.1\n",
    "test_frac = 0.5\n",
    "batch_size = 256\n",
    "shard_size = 256\n",
    "df_train = df.iloc[::1].query('dist > 0.01')\n",
    "print(df_train.shape)\n",
    "df_train = df_train.query('id_1 not in @benchmark_ids and id_2 not in @benchmark_ids')\n",
    "print(df_train.shape)\n",
    "df_train = df_train.iloc[:-(df_train.shape[0] % batch_size)]\n",
    "print(df_train.shape)\n",
    "\n",
    "\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X1, X2, y):\n",
    "        self.X1 = X1\n",
    "        self.X2 = X2\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.X1)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X1[idx], self.X2[idx], self.y[idx]\n",
    "if regen:\n",
    "    X1 = []\n",
    "    X2 = []\n",
    "    y = []\n",
    "    for i in trange(0, len(df_train.index), batch_size):\n",
    "        df_batch = df_train.iloc[i:i+batch_size]\n",
    "        X1.append(collate_batch([comp2graph(x) for x in df_batch['pretty_formula_1']]))\n",
    "        X2.append(collate_batch([comp2graph(x) for x in df_batch['pretty_formula_2']]))\n",
    "        y.append(torch.tensor(df_batch['dist'].values))\n",
    "\n",
    "        if (i // batch_size + 1) % shard_size == 0:\n",
    "            ds = MyDataset(X1, X2, y)\n",
    "            torch.save(ds, Path('full_dataset') / f'{(i // batch_size +1) // shard_size}.pt')\n",
    "            X1 = []\n",
    "            X2 = []\n",
    "            y = []\n",
    "\n",
    "    ds = MyDataset(X1, X2, y)\n",
    "    torch.save(ds, Path('full_dataset') / '0.pt')\n",
    "else:\n",
    "    # ds = torch.load(fn, weights_only=False)\n",
    "    dses = []\n",
    "    shards = sorted(Path('full_dataset').glob('*.pt'))\n",
    "    train_len = int((1 - test_frac) * len(shards))    \n",
    "    train_shards = shards[:train_len]\n",
    "    test_shards = shards[train_len:]\n",
    "    for shard in tqdm(train_shards):\n",
    "        dses.append(torch.load(shard, weights_only=False))\n",
    "    \n",
    "    ds = torch.utils.data.ConcatDataset(dses)\n",
    "    \n",
    "\n",
    "train_ds, val_ds = random_split(ds, [1 - val_frac, val_frac], generator=torch.Generator(device=device).manual_seed(123))\n",
    "train_dl = DataLoader(train_ds, batch_size=None, shuffle=True, generator=torch.Generator(device=device))\n",
    "val_dl = DataLoader(val_ds, batch_size=None)\n",
    "val_X1, val_X2, val_y = next(iter(val_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3e-3\n",
    "num_epochs = 2\n",
    "tau = 1.0\n",
    "elem_embed_dim: int = 64\n",
    "comp_embed_dim: int = 128\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "from model import CompositionEmbedding\n",
    "\n",
    "\n",
    "hist = []\n",
    "model = CompositionEmbedding(elem_input_dim=112, elem_hidden_dim=elem_embed_dim, comp_embed_dim=comp_embed_dim, rescale_init=np.sqrt(comp_embed_dim))\n",
    "model = torch.load('checkpoints/full-2.pt', weights_only=False).to(device)\n",
    "print(model.rescale)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.PolynomialLR(optimizer, total_iters=num_epochs)\n",
    "\n",
    "with trange(num_epochs * len(train_dl)) as bar:\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        loss_vals = []\n",
    "        for X1, X2, y in train_dl:\n",
    "            bar.update()            \n",
    "            loss_val = F.binary_cross_entropy(model(X1, X2), (y < tau).float())\n",
    "            loss_val.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            loss_vals.append(loss_val.detach().item())\n",
    "            if (bar.n + 1) % 100 == 0:\n",
    "                bar.set_description_str('Train: {:.3f} Valid: {:.3f}'.format(np.mean(loss_vals[-100:]),  hist[-1][\"Validation Loss\"] if hist else 0))\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_losses = []\n",
    "            for X1, X2, y in val_dl:\n",
    "                val_losses.append(F.binary_cross_entropy(model(X1, X2), (y < tau).float()))\n",
    "\n",
    "            val_losses = torch.tensor(val_losses)\n",
    "        hist.append({\n",
    "            'Epoch': epoch,\n",
    "            'Train Loss': sum(loss_vals) / len(loss_vals),\n",
    "            'Validation Loss': val_losses.mean().item()\n",
    "        })\n",
    "\n",
    "        print({k: f'{v:.4f}' for k, v in hist[-1].items()})\n",
    "\n",
    "        bar.set_description_str('Train: {:.3f} Valid: {:.3f}'.format(hist[-1][\"Train Loss\"], hist[-1][\"Validation Loss\"]))\n",
    "        scheduler.step()\n",
    "\n",
    "hist = pd.DataFrame(hist)\n",
    "\n",
    "sns.lineplot(hist, x='Epoch', y='Train Loss')\n",
    "sns.lineplot(hist, x='Epoch', y='Validation Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y < tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(X1, X2)[y < tau]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('2.044 < dist and dist < 2.045')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'checkpoints/full-2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = []\n",
    "ytrue = []\n",
    "for X1, X2, y in val_dl:\n",
    "    ypred.append(model(X1, X2).detach().cpu())\n",
    "    ytrue.append(y)\n",
    "\n",
    "ypred = torch.cat(ypred)\n",
    "ytrue = torch.cat(ytrue).cpu() < tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(((ypred > 0.5) == ytrue).float().mean())\n",
    "print(torch.corrcoef(torch.vstack([ypred > 0.5, ytrue]).float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(ypred[::100].numpy(force=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = torch.linalg.vector_norm(model.embed(X1) - model.embed(X2), dim=1).numpy(force=True)\n",
    "y_np = y.numpy(force=True) < tau\n",
    "\n",
    "sns.histplot(x=dists[y_np], label='y = 1', fill=False, element='step', bins=20)\n",
    "sns.histplot(x=dists[~y_np], label='y = 0', fill=False, element='step', bins=20)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train from CIF folder\n",
    "- oxidation state (BERTOS), make nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_id = 'mp-5615'\n",
    "\n",
    "df_id = df.query('id_1 == @mp_id')\n",
    "\n",
    "X1 = collate_batch([comp2graph(df_id['pretty_formula_1'].iloc[0])])\n",
    "\n",
    "x2s = df_id['pretty_formula_2']\n",
    "\n",
    "X2 = []\n",
    "for i in range(0, x2s.shape[0], batch_size):\n",
    "    X2.append(collate_batch([comp2graph(c) for c in x2s.iloc[i:i+batch_size]]))\n",
    "\n",
    "model.eval()\n",
    "z1 = model.embed(X1)\n",
    "z2 = torch.cat([model.embed(x) for x in X2])\n",
    "\n",
    "dists = torch.cdist(z1, z2)\n",
    "df_id['z_dist'] = dists.numpy(force=True).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id.sort_values('z_dist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baysic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
